{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all librarires\n",
    "import os\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set location of images and environmental conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location of the images.\n",
    "Drive =\"C:/\"\n",
    "Folder = \"YOUR FOLDER\"\n",
    "Mearsurements = \"YOUR SUB-FOLDER\"\n",
    "\n",
    "# Define the temperature (celsius) and pressure (mbar) for this calibration run\n",
    "current_temperature = 20\n",
    "current_pressure = 1005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 - Data preparation and inspection.\n",
    "Overview:\n",
    "- Load RAW images\n",
    "- Set a pixel threshold for the images\n",
    "- Crop images (Not advised for coulmn by coulmn calibration)\n",
    "- Inspect image histograms\n",
    "- Split images in RGB color channels and save as image stacks (replicate images are averraged)\n",
    "- Calculate mean intensity, standard deviation, red/green ratio for all pixels in images in the stacks + calculate mean red/green ratio for all individual columns\n",
    "- Save images with red/green ratio as pixel values\n",
    "- Insepct Ratio images for uneven distribution caused by uneven illumination by the LED (corrected with column by column calibration approach)\n",
    "- Optionally smooth the mean ratio column by column to reduce influence of artifacts on the optode during calibration \n",
    "- Save dataframe with mean red/green ratio column by column for all calibration data \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load RAW images and set minimum threshold pixel value for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the input directory\n",
    "input_dir = f'{Drive}/{Folder}/{Mearsurements}/'\n",
    "\n",
    "# Get a list of all image files in the input directory\n",
    "input_files = [f for f in os.listdir(input_dir) if f.endswith('.tiff')]\n",
    "input_files = natsorted(input_files)\n",
    "\n",
    "# Define the threshold value\n",
    "threshold_value = 256\n",
    "\n",
    "# Create a list to store the thresholded images\n",
    "thresholded_images = []\n",
    "\n",
    "# Calculate the number of rows and columns for the grid\n",
    "num_images = len(input_files)\n",
    "num_rows = int(num_images ** 0.5)\n",
    "num_cols = (num_images + num_rows - 1) // num_rows\n",
    "\n",
    "# Create the grid of subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 8))\n",
    "\n",
    "# Iterate over the image files and display them in the grid\n",
    "for i, filename in enumerate(input_files):\n",
    "    # Load the image\n",
    "    image = tifffile.imread(os.path.join(input_dir, filename))\n",
    "\n",
    "    # Apply the threshold\n",
    "    thresholded_image = np.where(image > threshold_value, image, 0)\n",
    "    thresholded_image_nan = np.where(thresholded_image == 0, np.nan, thresholded_image)\n",
    "\n",
    "    thresholded_images.append(thresholded_image_nan)\n",
    "\n",
    "    # Determine the subplot indices\n",
    "    row_idx = i // num_cols\n",
    "    col_idx = i % num_cols\n",
    "\n",
    "    # Display the thresholded image in the corresponding subplot\n",
    "    axes[row_idx, col_idx].imshow(thresholded_image, cmap='viridis', vmin=256,vmax=4065)\n",
    "    axes[row_idx, col_idx].set_title(filename[15:])\n",
    "    axes[row_idx, col_idx].axis('off')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "# Display the grid of images\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save thresholded images in new directory and display one example image to check crop settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory\n",
    "output_dir = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save Thresholded images\n",
    "for i, filename in enumerate(input_files):\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    tifffile.imwrite(output_path, thresholded_images[i])\n",
    "    \n",
    "# Set the path to the directory containing the thresholded images\n",
    "thresholded_dir = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/'\n",
    "\n",
    "# Get a list of all thresholded image files in the directory\n",
    "thresholded_files = [f for f in os.listdir(thresholded_dir) if f.endswith('.tiff')]\n",
    "thresholded_files = natsorted(thresholded_files)\n",
    "\n",
    "test_thresholded_image = tifffile.imread(os.path.join(thresholded_dir,thresholded_files[0]))\n",
    "# Fullsize crop setting[0:3040,0:4056] \n",
    "test_thresholded_image = test_thresholded_image[0:3040,0:4056] \n",
    "plt.imshow(test_thresholded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show histogram of Red, Green, and Blue color channel for each image in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for the grid\n",
    "num_images = len(thresholded_files)\n",
    "num_rows = int(num_images ** 0.5)\n",
    "num_cols = (num_images + num_rows - 1) // num_rows\n",
    "\n",
    "# Create the grid of subplots for histograms\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 8))\n",
    "\n",
    "# Iterate over the thresholded image files and display histograms in the grid\n",
    "for i, filename in enumerate(thresholded_files):\n",
    "    # Load the thresholded image\n",
    "    thresholded_image = tifffile.imread(os.path.join(thresholded_dir, filename))\n",
    "\n",
    "    # Set Crop dimension (OPTIONAL)\n",
    "    thresholded_image =thresholded_image[0:3040,0:4056] \n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    thresholded_image[np.isnan(thresholded_image)] = 0\n",
    "\n",
    "    # Get the color channels in Bayer order (BGGR)\n",
    "    red = thresholded_image[1::2, 1::2]\n",
    "    green1 = thresholded_image[0::2, 1::2]\n",
    "    green2 = thresholded_image[1::2, 0::2]\n",
    "    green = np.add(green1, green2) / 2\n",
    "    blue = thresholded_image[0::2, 0::2]\n",
    "\n",
    "    # Calculate the minimum and maximum value of the dataset\n",
    "    min_value_red = np.min(red)\n",
    "    min_value_green = np.min(green)\n",
    "    min_value_blue = np.min(blue)\n",
    "    max_value_red = np.max(red)\n",
    "    max_value_green = np.max(green)\n",
    "    max_value_blue = np.max(blue)\n",
    "    min_value = min(min_value_red, min_value_green, min_value_blue)\n",
    "    max_value = max(max_value_red, max_value_green, max_value_blue)\n",
    "\n",
    "   # Calculate and plot the histograms for each color channel\n",
    "    if np.isfinite(min_value) and np.isfinite(max_value):\n",
    "        histogram, bin_edges = np.histogram(red, bins=4095, range=(threshold_value, max_value))\n",
    "        axes[i // num_cols, i % num_cols].plot(bin_edges[0:-1], histogram, color='red', linewidth=1)\n",
    "\n",
    "        histogram, bin_edges = np.histogram(green, bins=4095, range=(threshold_value, max_value))\n",
    "        axes[i // num_cols, i % num_cols].plot(bin_edges[0:-1], histogram, color='green', linewidth=1)\n",
    "\n",
    "        histogram, bin_edges = np.histogram(blue, bins=4095, range=(threshold_value, max_value))\n",
    "        axes[i // num_cols, i % num_cols].plot(bin_edges[0:-1], histogram, color='blue', linewidth=1)\n",
    "\n",
    "    # Set the title of the subplot as the filename\n",
    "    axes[i // num_cols, i % num_cols].set_title(filename[15:])\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(hspace=1.5, wspace=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create and save image stacks of each color channel.\n",
    "- Stack averages are made for replicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/'\n",
    "output_path = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/Stacks'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "input_files = [f for f in os.listdir(input_dir) if f.endswith('.tiff')]\n",
    "input_files = natsorted(input_files)\n",
    "\n",
    "# Group files by the identifying number\n",
    "groups = defaultdict(list)\n",
    "for file in input_files:\n",
    "    numeric_num = float(os.path.splitext(file)[0][24:].replace(\",\", \".\"))\n",
    "    groups[numeric_num].append(file)\n",
    "\n",
    "# Initialize lists to store the averaged channel stacks\n",
    "averaged_red_stack = []\n",
    "averaged_green_stack = []\n",
    "averaged_blue_stack = []\n",
    "\n",
    "for numeric_num, files in groups.items():\n",
    "    red_accumulator = []\n",
    "    green_accumulator = []\n",
    "    blue_accumulator = []\n",
    "\n",
    "    # Load and accumulate each replicate image\n",
    "    for file in files:\n",
    "        img = tifffile.imread(os.path.join(input_dir, file))\n",
    "\n",
    "         ### Set Crop dimension (OPTIONAL) ### No crop setting: [0:3040,0:4056]\n",
    "        img = img[0:3040,0:4056]  \n",
    "        \n",
    "        red_channel = img[1::2, 1::2]\n",
    "        blue_channel = img[0::2, 0::2]\n",
    "        green_channel_1 = img[0::2, 1::2]\n",
    "        green_channel_2 = img[1::2, 0::2]\n",
    "        green_channel = np.add(green_channel_1, green_channel_2) // 2\n",
    "\n",
    "        red_accumulator.append(red_channel)\n",
    "        blue_accumulator.append(blue_channel)\n",
    "        green_accumulator.append(green_channel)\n",
    "    \n",
    "    # Calculate the average of replicates for each channel\n",
    "    red_avg = np.mean(red_accumulator, axis=0)\n",
    "    green_avg = np.mean(green_accumulator, axis=0)\n",
    "    blue_avg = np.mean(blue_accumulator, axis=0)\n",
    "    \n",
    "    # Add the averaged channels to the corresponding stacks\n",
    "    averaged_red_stack.append(red_avg)\n",
    "    averaged_green_stack.append(green_avg)\n",
    "    averaged_blue_stack.append(blue_avg)\n",
    "\n",
    "# Stack the averaged channels along the third axis\n",
    "averaged_red_stack = np.stack(averaged_red_stack, axis=0)\n",
    "averaged_green_stack = np.stack(averaged_green_stack, axis=0)\n",
    "averaged_blue_stack = np.stack(averaged_blue_stack, axis=0)\n",
    "\n",
    "# Save the averaged stacks to separate TIFF files\n",
    "tifffile.imwrite(os.path.join(output_path, \"averaged_stacked_red_channel.tiff\"), averaged_red_stack)\n",
    "tifffile.imwrite(os.path.join(output_path, \"averaged_stacked_green_channel.tiff\"), averaged_green_stack)\n",
    "tifffile.imwrite(os.path.join(output_path, \"averaged_stacked_blue_channel.tiff\"), averaged_blue_stack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load image stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/Stacks'\n",
    "# Get a list of all TIFF files in the directory\n",
    "files = [f for f in os.listdir(output_path) if f.endswith('.tiff')]\n",
    "print(files)\n",
    "\n",
    "green_stack = tifffile.imread(os.path.join(output_path, files[1]))\n",
    "red_stack = tifffile.imread(os.path.join(output_path, files[2]))\n",
    "blue_stack = tifffile.imread(os.path.join(output_path, files[0]))\n",
    "\n",
    "#Get length of image stacks\n",
    "num_images_green = len(green_stack)\n",
    "num_images_red = len(red_stack)\n",
    "num_images_blue = len(blue_stack)\n",
    "if num_images_green == num_images_red and num_images_blue:\n",
    "    print(\"Equal stacks\")    \n",
    "else:\n",
    "    print(\"unequal stacks\")\n",
    "\n",
    "num_images = num_images_green\n",
    "num_columns = green_stack[0].shape[1]# Define the number of columns per image\n",
    "\n",
    "print(\"number of images in stack:\",num_images)\n",
    "print(\"number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Red/Green intensity ratio and save ratio images in new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/Ratio_Images/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "mean_red_intensity =[]\n",
    "mean_green_intensity = []\n",
    "mean_blue_intensity = []\n",
    "std_red_intensity = []\n",
    "std_green_intensity = []\n",
    "std_blue_intensity =[]\n",
    "\n",
    "# Initialize lists to store column-wise means and stds for the red/green ratio\n",
    "mean_red_green_ratio_per_column = []\n",
    "std_red_green_ratio_per_column = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    mean_red_intensity.append(np.mean(red_stack[i]))\n",
    "    mean_green_intensity.append(np.mean(green_stack[i]))\n",
    "    mean_blue_intensity.append(np.mean(blue_stack[i]))\n",
    "    std_red_intensity.append(np.std(red_stack[i]))\n",
    "    std_green_intensity.append(np.std(green_stack[i]))\n",
    "    std_blue_intensity.append(np.std(blue_stack[i]))\n",
    "\n",
    "    # Calculate the intensity ratio for each pixel\n",
    "    ratio = red_stack[i] / green_stack[i]\n",
    "\n",
    "    # Construct the output file path\n",
    "    output_file = os.path.join(output_path, f\"ratio_image_{i}.tiff\")\n",
    "    # Save the new image\n",
    "    tifffile.imwrite(output_file, ratio)\n",
    "\n",
    "    # Calculate the mean and std of the ratio for each column\n",
    "    mean_ratio_per_column = np.mean(ratio, axis=0)  # Average across rows for each column\n",
    "    std_ratio_per_column = np.std(ratio, axis=0)    # Standard deviation across rows for each column\n",
    "\n",
    "    mean_red_green_ratio_per_column.append(mean_ratio_per_column)\n",
    "    std_red_green_ratio_per_column.append(std_ratio_per_column)\n",
    "\n",
    "# Output the column-wise means for the first image as an example\n",
    "print(mean_red_green_ratio_per_column[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Load two individual ratio images and display ratio histograms for vertially distinct sections in the image to check for uneven illumination patterns. \n",
    "- Displays column averages for all images in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first image\n",
    "image1_path = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/Ratio_Images/ratio_image_0.tiff'\n",
    "image1 = tifffile.imread(image1_path)\n",
    "\n",
    "# Load the second image\n",
    "image2_path = f'{Drive}/{Folder}/{Mearsurements}/Threshold_images/Ratio_Images/ratio_image_10.tiff'\n",
    "image2 = tifffile.imread(image2_path)\n",
    "\n",
    "# Number of sections to divide the images into\n",
    "num_sections = 10\n",
    "section_width1 = image1.shape[1] // num_sections\n",
    "section_width2 = image2.shape[1] // num_sections\n",
    "\n",
    "# Calculate the median for the entire image\n",
    "median_value_1 = np.median(image1)\n",
    "median_value_2 = np.median(image2)\n",
    "\n",
    "# Plotting setup\n",
    "plt.figure(figsize=(12, 6))\n",
    "#plt.title('Histograms of Vertical Sections for Two Images', fontsize=14) # Change title size here\n",
    "plt.xlabel('Red/Green Ratio', fontsize=20) # Change x-axis label size here\n",
    "plt.ylabel('Frequency', fontsize=20) # Change y-axis label size here\n",
    "plt.xticks(fontsize=16) # Change x-axis tick size here\n",
    "plt.yticks(fontsize=16) # Change y-axis tick size here\n",
    "\n",
    "# Function to plot histograms for each section of an image\n",
    "def plot_histograms(image, section_width, image_label, add_legend):\n",
    "    for i in range(num_sections):\n",
    "        # Extract the section\n",
    "        section = image[:, i*section_width:(i+1)*section_width]\n",
    "\n",
    "        # Calculate the histogram for the section\n",
    "        histogram, bin_edges = np.histogram(section, bins=150, range=[np.min(image),np.max(image)])\n",
    "\n",
    "        # Plot the histogram\n",
    "        if add_legend:\n",
    "            plt.plot(bin_edges[0:-1], histogram, label=f'Section {i+1}')\n",
    "        else:\n",
    "            plt.plot(bin_edges[0:-1], histogram)\n",
    "\n",
    "# Plot histograms for the first image with legend\n",
    "plot_histograms(image1, section_width1, 'Image 1', True)\n",
    "\n",
    "# Plot histograms for the second image without adding to legend\n",
    "plot_histograms(image2, section_width2, 'Image 2', False)\n",
    "# Add a line for the median\n",
    "plt.axvline(median_value_1, color='k', linestyle='dashed', linewidth=2, label='Median: 0% Air Sat.')\n",
    "plt.axvline(median_value_2, color='red', linestyle='dashed', linewidth=2, label='Median: 100% Air Sat.')\n",
    "plt.legend(fontsize=13)\n",
    "plt.savefig(\"Calbration_ratio_distribution.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# plot mean ratios per column for each image\n",
    "for i, mean_ratio in enumerate(mean_red_green_ratio_per_column):\n",
    "    plt.plot(mean_ratio, label=f'Image {i+1}')\n",
    "\n",
    "plt.xlabel('Column Index')\n",
    "plt.ylabel('Mean Red/Green Ratio')\n",
    "plt.title('Mean Red/Green Ratio per Column Across All Images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Displays linear, 2nd degree polynominal and 3rd degree polynomial fits on average coulmn values for all images in the directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dictionaries for storing polynomial coefficients and smoothed data\n",
    "polynomial_coefficients_linear = {}\n",
    "polynomial_coefficients_2nd = {}\n",
    "polynomial_coefficients_3rd = {}\n",
    "smoothed_data_linear = {}\n",
    "smoothed_data_2nd = {}\n",
    "smoothed_data_3rd = {}\n",
    "\n",
    "# Specify which regression types to plot (can be 'linear', '2nd', '3rd', or any combination)\n",
    "regression_types_to_plot = ['linear', '2nd', '3rd']  # Adjust this list based on your needs\n",
    "\n",
    "# Number of images you're working with\n",
    "num_images = len(mean_red_green_ratio_per_column)\n",
    "\n",
    "# Calculate the number of columns based on regression types to plot\n",
    "num_cols = len(regression_types_to_plot)\n",
    "\n",
    "# Determine the grid size\n",
    "grid_rows = num_images  # One row per image\n",
    "grid_cols = num_cols  # Columns based on the number of regression types\n",
    "fig_width = 15  # Width of the figure, adjust as necessary\n",
    "fig_height = 5 * num_images  # Height of the figure, adjust based on the number of images\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "# Iterate over each image's mean red/green ratio per column\n",
    "for i, mean_ratio in enumerate(mean_red_green_ratio_per_column):\n",
    "    column_indices = np.arange(len(mean_ratio))\n",
    "    \n",
    "    # Perform polynomial regressions of degrees 1, 2, and 3\n",
    "    coeffs_linear = np.polyfit(column_indices, mean_ratio, 1)\n",
    "    coeffs_2nd = np.polyfit(column_indices, mean_ratio, 2)\n",
    "    coeffs_3rd = np.polyfit(column_indices, mean_ratio, 3)\n",
    "    \n",
    "    # Generate polynomial functions from coefficients\n",
    "    poly_func_linear = np.poly1d(coeffs_linear)\n",
    "    poly_func_2nd = np.poly1d(coeffs_2nd)\n",
    "    poly_func_3rd = np.poly1d(coeffs_3rd)\n",
    "    \n",
    "    # Calculate fitted values for all regression types\n",
    "    fitted_vals_linear = poly_func_linear(column_indices)\n",
    "    fitted_vals_2nd = poly_func_2nd(column_indices)\n",
    "    fitted_vals_3rd = poly_func_3rd(column_indices)\n",
    "\n",
    "    # Calculate R^2 scores\n",
    "    r2_linear = r2_score(mean_ratio, fitted_vals_linear)\n",
    "    r2_2nd = r2_score(mean_ratio, fitted_vals_2nd)\n",
    "    r2_3rd = r2_score(mean_ratio, fitted_vals_3rd)\n",
    "\n",
    "    # Save coefficients, smoothed data, and R^2 scores\n",
    "    polynomial_coefficients_linear[f'Image {i}'] = coeffs_linear\n",
    "    polynomial_coefficients_2nd[f'Image {i}'] = coeffs_2nd\n",
    "    polynomial_coefficients_3rd[f'Image {i}'] = coeffs_3rd\n",
    "\n",
    "    smoothed_data_linear[f'Image {i}'] = fitted_vals_linear\n",
    "    smoothed_data_2nd[f'Image {i}'] = fitted_vals_2nd\n",
    "    smoothed_data_3rd[f'Image {i}'] = fitted_vals_3rd\n",
    "    \n",
    "    # Plotting logic for each regression type with R^2 score included in the title\n",
    "    for j, reg_type in enumerate(regression_types_to_plot):\n",
    "        ax = plt.subplot(grid_rows, grid_cols, i * num_cols + j + 1)\n",
    "        ax.plot(column_indices, mean_ratio, 'o', label='Original data')\n",
    "        \n",
    "        if reg_type == 'linear':\n",
    "            ax.plot(column_indices, fitted_vals_linear, 'b-', label='Linear Fit')\n",
    "            ax.set_title(f'Image {i+1} - Linear, R^2={r2_linear:.4f}')\n",
    "        elif reg_type == '2nd':\n",
    "            ax.plot(column_indices, fitted_vals_2nd, 'r-', label='2nd Degree Fit')\n",
    "            ax.set_title(f'Image {i+1} - 2nd Degree, R^2={r2_2nd:.4f}')\n",
    "        elif reg_type == '3rd':\n",
    "            ax.plot(column_indices, fitted_vals_3rd, 'g-', label='3rd Degree Fit')\n",
    "            ax.set_title(f'Image {i+1} - 3rd Degree, R^2={r2_3rd:.4f}')\n",
    "        \n",
    "        ax.legend()\n",
    "\n",
    "# Adjust layout for better spacing and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create dataframe for calibration data with RAW data and smoothed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir = f'{Drive}/{Folder}/{Mearsurements}/' \n",
    "files = [f for f in os.listdir(files_dir) if f.endswith('.tiff')]\n",
    "files = natsorted(files)\n",
    "\n",
    "# Updated df_ratios to include original and both 2nd and 3rd degree smoothed ratios\n",
    "if 'df_ratios' not in globals():\n",
    "    df_ratios = pd.DataFrame(columns=['Image ID', 'Oxygen%', 'Column Index', 'Original Ratio', '2nd Degree Smoothed Ratio',\n",
    "                                      '3rd Degree Smoothed Ratio', 'Linear Smoothed Ratio', 'Temp', 'Atmospheric Pressure'])\n",
    "\n",
    "# Set the fixed number of iterations based on number of image sin the stacks\n",
    "fixed_iterations = num_images \n",
    "\n",
    "for i in range(num_images):\n",
    "    key = f\"Image {i}\"\n",
    "    # Ensure we have smoothed data for both polynomial degrees; if not, skip the current iteration\n",
    "    if key not in smoothed_data_2nd or key not in smoothed_data_3rd:\n",
    "        print(f\"Skipping: {key} not found in smoothed_data for either 2nd or 3rd degree.\")\n",
    "        continue\n",
    "\n",
    "    file_name = files[i]\n",
    "    numeric_num = float(os.path.splitext(file_name)[0][24:].replace(\",\", \".\"))\n",
    "\n",
    "    # Original data for the current image\n",
    "    original_values = mean_red_green_ratio_per_column[i]\n",
    "    num_columns = len(original_values)\n",
    "\n",
    "    smoothed_values_2nd = smoothed_data_2nd[key]\n",
    "    smoothed_values_3rd = smoothed_data_3rd[key]\n",
    "    smoothed_linear = smoothed_data_linear[key]\n",
    "\n",
    "    # Prepare data for the current image, including temperature and original + smoothed ratios\n",
    "    rows_to_add = [{'Image ID': i+1,\n",
    "                    'Oxygen%': numeric_num,\n",
    "                    'Column Index': col,\n",
    "                    'Original Ratio': original_values[col],\n",
    "                    '2nd Degree Smoothed Ratio': smoothed_values_2nd[col],\n",
    "                    '3rd Degree Smoothed Ratio': smoothed_values_3rd[col],\n",
    "                    'Linear Smoothed Ratio': smoothed_linear[col],\n",
    "                    'Temp': current_temperature,\n",
    "                    'Atmospheric Pressure':current_pressure} for col in range(num_columns)]\n",
    "\n",
    "    # Append new rows to df_ratios\n",
    "    df_ratios = pd.concat([df_ratios, pd.DataFrame(rows_to_add)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optionally apply below block to convert air saturation (%) to oxygen partial pressure (hPa) in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partial_pressure_o2(row, solubility_dict):\n",
    "    # Interpolate or directly use oxygen solubility from the dictionary\n",
    "    temperatures = np.array(list(solubility_dict.keys()))\n",
    "    if row['Temp'] in solubility_dict:\n",
    "        solubility_umol_L = solubility_dict[row['Temp']]\n",
    "    else:\n",
    "        # Simple interpolation for temperatures not directly available in the dictionary\n",
    "        closest_temp = min(temperatures, key=lambda x: abs(x - row['Temp']))\n",
    "        solubility_umol_L = solubility_dict[closest_temp]\n",
    "\n",
    "    # Convert solubility from umol/L to mg/L (using oxygen's molar mass, 32.00 g/mol)\n",
    "    solubility_mg_L = solubility_umol_L * 32.00 / 1000\n",
    "\n",
    "    # Adjust concentration based on air saturation percentage\n",
    "    C_O2 = solubility_mg_L * (row['Oxygen%'] / 100.0)\n",
    "\n",
    "    # Calculate partial pressure of O2 in water based on Henry's Law\n",
    "    # Here, we use atmospheric pressure and O2 percentage to approximate P_O2 for 100% saturation\n",
    "    oxygen_percentage_in_air = 0.21\n",
    "    P_O2_atm = row['Atmospheric Pressure'] * oxygen_percentage_in_air  # Partial pressure of O2 in atmosphere\n",
    "    P_O2 = P_O2_atm * (row['Oxygen%'] / 100.0)  # Adjust for actual air saturation\n",
    "\n",
    "    return P_O2\n",
    "\n",
    "Oxygen_solubility_dict = {0: 456.6, 1: 444.0, 2: 431.9,3: 420.4,4: 409.4,5: 398.9,6: 388.8,7: 379.2,8: 369.9,9: 361.1,10: 352.6,11: 344.4,12: 336.6,13: 329.1,14: 321.9,15: 314.9,16: 308.3,17: 301.8,18: 295.6,19: 289.7,20: 283.9,21: 278.3,22: 273.0,23: 267.8,24: 262.8,25: 257.9,26: 253.2,27: 248.7,28: 244.3,29: 240.0,30: 235.9,31: 231.9,32: 228.0,33: 224.2,34: 220.5,35: 217.0,36: 213.5,37: 210.1,38: 206.7,39: 203.5,40: 200.4}\n",
    "\n",
    "# Apply the function to calculate partial pressure of O2 in hPa\n",
    "df_ratios['hPa'] = df_ratios.apply(calculate_partial_pressure_o2, args=(Oxygen_solubility_dict,), axis=1)\n",
    "\n",
    "df_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> - Go back to start and run calibration data with other temperatures to add them to the Dataframe (df_ratios). Save to Excel file when all data is added and continue. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename and path for the Excel file you want to save\n",
    "excel_file_path = f'{Drive}/{Folder}/RAW_Calibration_data.xlsx'\n",
    "\n",
    "# Save the DataFrame as an Excel file\n",
    "df_ratios.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Output the DataFrame (optional, you might want to print a confirmation message instead)\n",
    "print(f'DataFrame saved as Excel file at: {excel_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
